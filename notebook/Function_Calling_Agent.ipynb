{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/head1ton/llm_a_z_finetuning/blob/main/notebook/Function_Calling_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RRYSu48huSUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1fb7901-2062-4c03-a682-b38b66b9fbb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m154.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.6/84.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.9/475.9 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain openai tiktoken yfinance langchain_community langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"여러분의 Key 값\""
      ],
      "metadata": {
        "id": "dNA4TsHpu6OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aX8ZDhm0u-gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Literal\n",
        "\n",
        "# from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "# load_dotenv()\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "def _resolve_api_context() -> tuple[str, str]:\n",
        "    \"\"\"선택된 API 키와 베이스 URL 정보를 반환합니다.\"\"\"\n",
        "    # api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "    api_key = userdata.get('OPENROUTER_API_KEY')\n",
        "\n",
        "    if not api_key:\n",
        "        raise RuntimeError(\"OPENROUTER_API_KEY가 필요합니다.\")\n",
        "\n",
        "    base_url = os.getenv(\"OPENROUTER_API_BASE\") or \"https://openrouter.ai/api/v1\"\n",
        "\n",
        "    return (api_key, base_url)\n",
        "\n",
        "\n",
        "def create_openrouter_llm(\n",
        "    model: str = \"openai/gpt-4.1-mini\",\n",
        "    temperature: float = 0.3,\n",
        "    max_tokens: int | None = None,\n",
        "    **kwargs: object,\n",
        ") -> ChatOpenAI:\n",
        "    \"\"\"OpenAI 호환 LLM 생성 헬퍼.\n",
        "\n",
        "    Args:\n",
        "        model: 모델 이름. OpenRouter에서는 provider/model 형식 사용 가능\n",
        "               (예: openai/gpt-4o, anthropic/claude-3-sonnet, google/gemini-pro)\n",
        "        temperature: 생성 온도 (0.0-2.0)\n",
        "        max_tokens: 최대 생성 토큰 수\n",
        "\n",
        "    Returns:\n",
        "        ChatOpenAI: 설정된 LLM 인스턴스\n",
        "    \"\"\"\n",
        "    api_key, base_url = _resolve_api_context()\n",
        "\n",
        "    openai_kwargs: dict = {\n",
        "        \"model\": model,\n",
        "        \"api_key\": api_key,\n",
        "        \"temperature\": temperature,\n",
        "        \"max_retries\": 3,\n",
        "        \"timeout\": 60,\n",
        "        **kwargs,\n",
        "    }\n",
        "    if max_tokens is not None:\n",
        "        openai_kwargs[\"max_tokens\"] = max_tokens\n",
        "    if base_url:\n",
        "        openai_kwargs[\"base_url\"] = base_url\n",
        "    return ChatOpenAI(**openai_kwargs)\n",
        "\n",
        "def create_embedding_model(\n",
        "    model: str = \"openai/text-embedding-3-small\",\n",
        "    **kwargs,\n",
        ") -> OpenAIEmbeddings:\n",
        "    \"\"\"OpenAI 호환 임베딩 모델 생성.\n",
        "\n",
        "    Args:\n",
        "        model: 임베딩 모델 이름. OpenRouter에서는 provider/model 형식 사용 가능\n",
        "               (예: openai/text-embedding-3-small, openai/text-embedding-3-large)\n",
        "        **kwargs: 추가 파라미터 (encoding_format 등은 model_kwargs로 전달됨)\n",
        "\n",
        "    Returns:\n",
        "        OpenAIEmbeddings: 설정된 임베딩 모델 인스턴스\n",
        "    \"\"\"\n",
        "    api_key, base_url = _resolve_api_context()\n",
        "\n",
        "    # 전달받은 kwargs에서 model_kwargs로 전달할 파라미터 분리\n",
        "    # encoding_format, extra_headers 등은 model_kwargs로 전달\n",
        "    model_kwargs: dict = {}\n",
        "    embedding_kwargs: dict = {\n",
        "        \"model\": model,\n",
        "        \"api_key\": api_key,\n",
        "        \"show_progress_bar\": True,\n",
        "        \"skip_empty\": True,\n",
        "    }\n",
        "\n",
        "    # 전달받은 kwargs 처리\n",
        "    for key, value in kwargs.items():\n",
        "        # OpenRouter API 특정 파라미터는 model_kwargs로 전달\n",
        "        if key in (\"encoding_format\"):\n",
        "            model_kwargs[key] = value\n",
        "        else:\n",
        "            # 나머지는 OpenAIEmbeddings에 직접 전달\n",
        "            embedding_kwargs[key] = value\n",
        "\n",
        "    if base_url:\n",
        "        embedding_kwargs[\"base_url\"] = base_url\n",
        "\n",
        "    # model_kwargs가 있으면 전달\n",
        "    if model_kwargs:\n",
        "        embedding_kwargs[\"model_kwargs\"] = model_kwargs\n",
        "\n",
        "    return OpenAIEmbeddings(**embedding_kwargs)\n",
        "\n",
        "\n",
        "def create_embedding_model_direct(\n",
        "    model: str = \"qwen/qwen3-embedding-0.6b\",\n",
        "    encoding_format: Literal[\"float\", \"base64\"] = \"float\",\n",
        "    input_text: str | list[str] = \"\",\n",
        "    **kwargs,\n",
        ") -> list[float] | list[list[float]]:\n",
        "    \"\"\"OpenAI SDK를 직접 사용하여 임베딩 생성 (encoding_format 지원).\n",
        "\n",
        "    LangChain의 OpenAIEmbeddings가 encoding_format을 지원하지 않을 때 사용.\n",
        "\n",
        "    Args:\n",
        "        model: 임베딩 모델 이름\n",
        "        encoding_format: 인코딩 형식 (\"float\")\n",
        "        input_text: 임베딩할 텍스트 (문자열 또는 문자열 리스트)\n",
        "        **kwargs: 추가 파라미터\n",
        "\n",
        "    Returns:\n",
        "        임베딩 벡터 리스트 (단일 텍스트) 또는 리스트의 리스트 (여러 텍스트)\n",
        "    \"\"\"\n",
        "    from openai import OpenAI\n",
        "\n",
        "    api_key, base_url = _resolve_api_context()\n",
        "\n",
        "    client = OpenAI(\n",
        "        base_url=base_url,\n",
        "        api_key=api_key,\n",
        "    )\n",
        "\n",
        "    # input_text가 비어있으면 kwargs에서 가져오기\n",
        "    if not input_text:\n",
        "        input_text = kwargs.get(\"input\", \"\")\n",
        "\n",
        "    response = client.embeddings.create(\n",
        "        model=model,\n",
        "        input=input_text,\n",
        "        encoding_format=encoding_format,\n",
        "    )\n",
        "\n",
        "    # 단일 텍스트인 경우 첫 번째 임베딩 반환\n",
        "    if isinstance(input_text, str):\n",
        "        return response.data[0].embedding\n",
        "    else:\n",
        "        # 여러 텍스트인 경우 모든 임베딩 반환\n",
        "        return [item.embedding for item in response.data]\n",
        "\n",
        "\n",
        "def get_available_model_types() -> dict[str, list[str]]:\n",
        "    \"\"\"OpenRouter에서 사용 가능한 모델 유형을 반환합니다.\n",
        "\n",
        "    Returns:\n",
        "        dict[str, list[str]]: 모델 유형별 모델 목록\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"chat\": [\n",
        "            \"openai/gpt-4.1\",\n",
        "            \"openai/gpt-4.1-mini\",\n",
        "            \"openai/gpt-5\",\n",
        "            \"openai/gpt-5-mini\",\n",
        "            \"anthropic/claude-sonnet-4.5\",\n",
        "            \"anthropic/claude-haiku-4.5\",\n",
        "            \"google/gemini-2.5-flash-preview-09-2025\",\n",
        "            \"google/gemini-pro-2.5\",\n",
        "            \"x-ai/grok-4-fast\",\n",
        "            \"moonshotai/kimi-k2-thinking\",\n",
        "            \"liquid/lfm-2.2-6b\",\n",
        "            \"z-ai/glm-4.6\",\n",
        "        ],\n",
        "        \"embedding\": [\n",
        "            \"openai/text-embedding-3-small\",\n",
        "            \"openai/text-embedding-3-large\",\n",
        "            \"google/gemini-embedding-001\",\n",
        "            \"qwen/qwen3-embedding-0.6b\",\n",
        "            \"qwen/qwen3-embedding-4b\",\n",
        "            \"qwen/qwen3-embedding-8b\",\n",
        "        ],\n",
        "    }\n",
        "\n",
        "\n",
        "embeddings = create_embedding_model()\n",
        "llm = create_openrouter_llm()"
      ],
      "metadata": {
        "id": "G4330Vv-eV8c"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "# from src.llm.client import create_openrouter_llm\n",
        "\n",
        "# LLM은 한 번만 생성해서 재사용 (중요)\n",
        "llm = create_openrouter_llm(\n",
        "    model=\"openai/gpt-oss-20b:free\",  # 또는 openai/gpt-4o, gpt-oss-20b 등\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "c-1S2tb7oHJ9"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Calling 함수 명세 예시"
      ],
      "metadata": {
        "id": "tGsd4tc_WC9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function Calling은 `LLM에게 함수에 대해서 설명`하고, 사용자의 요청 사항이 해당 함수를 통해 풀어야 하는 문제라고 판단되면 함수를 호출하는 태스크입니다.  \n",
        "\n",
        "앞서 배웠던 ReAct 에이전트와 매우 유사하지만, ReAct 에이전트와는 달리 일반적으로는 별도의 `생각` 과정을 거치지 않고 호출한다는 점이 특징입니다.  \n",
        "\n",
        "`LLM에게 함수에 대해서 설명하는 방식`이 정형화 된 편인데 이 부분을 유념하면 큰 어려움은 없을 것입니다."
      ],
      "metadata": {
        "id": "JyWWWLHAcbVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Calling 실습"
      ],
      "metadata": {
        "id": "5nZh9VK2dZ2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 함수 명세에 대한 간단 예시"
      ],
      "metadata": {
        "id": "0aOMX8logkFm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반적으로 Function Calling을 하기 위해서는 함수의 명세를 아래와 같은 형식으로 작성해야 합니다.  \n",
        "\n",
        "LLM에게 아래의 함수 명세를 전달하면 LLM은 사용자가 특정 도시나 주에 대해서 온도 단위만 알면 함수를 호출할 수 있다는 것을 인지한 상태에서 사용자가 특정 지역의 온도를 물어보면 함수를 호출할 것입니다."
      ],
      "metadata": {
        "id": "R6Rrdvd7xEl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "functions = [\n",
        "   {\n",
        "       \"name\": \"get_current_weather\",\n",
        "       \"description\": \"현재 날씨 정보 가져오기\",\n",
        "       \"parameters\": {\n",
        "           \"type\": \"object\",\n",
        "           \"properties\": {\n",
        "               \"location\": {\n",
        "                   \"type\": \"string\",\n",
        "                   \"description\": \"도시와 주/도, 예: San Francisco, CA\",\n",
        "               },\n",
        "               \"format\": {\n",
        "                   \"type\": \"string\",\n",
        "                   \"enum\": [\"celsius\", \"fahrenheit\"],\n",
        "                   \"description\": \"사용할 온도 단위. 사용자의 위치에서 이를 추론합니다.\",\n",
        "               },\n",
        "           },\n",
        "           \"required\": [\"location\", \"format\"],\n",
        "       },\n",
        "   }\n",
        "]"
      ],
      "metadata": {
        "id": "VoCQg4K_gu31"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 야후파이낸스 함수 셋팅"
      ],
      "metadata": {
        "id": "HqwsGJDhvAQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function Calling 문제를 풀어보기 위해서는 호출할 수 있는 함수가 먼저 있어야 할 것입니다. 우리가 실제로 사용할 함수를 작성합니다.  \n",
        "해당 함수는 미국 주식 심볼을 입력하면 해당 주식의 종가를 반환하는 함수입니다."
      ],
      "metadata": {
        "id": "-PIfFDHodgRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "\n",
        "def get_stock_price(symbol):\n",
        "    \"\"\"\n",
        "    주어진 주식 심볼의 최신 종가를 반환하는 함수\n",
        "\n",
        "    :param symbol: 주식 심볼 (예: 'AAPL' for Apple Inc.)\n",
        "    :return: 소수점 둘째 자리까지 반올림된 최신 종가\n",
        "    \"\"\"\n",
        "    ticker = yf.Ticker(symbol)\n",
        "    todays_data = ticker.history(period='1d')\n",
        "    return round(todays_data['Close'].iloc[0], 2)"
      ],
      "metadata": {
        "id": "YRI5440YQQGC"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_stock_price('AAPL'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZUL_S4s89_W",
        "outputId": "8e7b5357-bc95-4dd8-98d7-436d94a8c9a1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "278.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_stock_price('GOOG'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wg282JoTCyx",
        "outputId": "30084c96-aca1-40cf-db0f-096785cef991"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "310.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_stock_price('NVDA'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT3lQzrlzGE9",
        "outputId": "3d1847db-0891-4430-b792-583c307266a2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up tools"
      ],
      "metadata": {
        "id": "bu0S2hVvhL9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "함수를 작성하면 끝난 것이 아닙니다. Function Calling을 하기 위해서는 해당 함수를 특정 형식으로 작성해야 합니다."
      ],
      "metadata": {
        "id": "3IkgVhe1d2MU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import BaseTool\n",
        "from typing import Optional, Type\n",
        "from langchain_classic.agents import initialize_agent, Tool, AgentType\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "HMsQheoUhOWy"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 입력 데이터 형식 정의 (첫 번째 클래스)"
      ],
      "metadata": {
        "id": "86vhtiVvQPmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 부분은 함수에 어떤 데이터가.필요한지 정의합니다. 여기서는:\n",
        "\n",
        "- StockPriceCheckInput이라는 클래스를 만듭니다.\n",
        "이 클래스는 stockticker라는 문자열 데이터가 필요하다고 정의합니다 (예: \"AAPL\").\n",
        "Field(...)는 이 데이터가 반드시 필요하다는 뜻입니다.\n",
        "\n",
        "왜 이런 클래스가 필요할까요? AI가 이 도구를 사용할 때 \"어떤 형식의 데이터를 넣어야 하는지\" 알 수 있게 해줍니다. 마치 입력 양식과 같은 역할입니다."
      ],
      "metadata": {
        "id": "uH0SOZ8AQTbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class StockPriceCheckInput(BaseModel):\n",
        "    \"\"\"Input for Stock price check.\"\"\"\n",
        "\n",
        "    stockticker: str = Field(..., description=\"Ticker symbol for stock or index\")"
      ],
      "metadata": {
        "id": "Qdcr69QZoFJm"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 도구 정의 (두 번째 클래스)\n"
      ],
      "metadata": {
        "id": "jUrHSGhiQQMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StockPriceTool(BaseTool):\n",
        "    name: str = \"get_stock_ticker_price\"\n",
        "    description: str = \"주식 가격을 알아야 할 때 유용합니다. yfinance API에서 사용되는 주식 티커(종목 코드)를 입력해야 합니다.\"\n",
        "\n",
        "    def _run(self, stockticker: str):\n",
        "        # print(\"i'm running\")\n",
        "        price_response = get_stock_price(stockticker)\n",
        "        return price_response\n",
        "\n",
        "    args_schema: Optional[Type[BaseModel]] = StockPriceCheckInput"
      ],
      "metadata": {
        "id": "BiWuFYxzmDyR"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 부분은 실제 AI가 사용할 수 있는 도구를 만듭니다:\n",
        "\n",
        "- StockPriceTool이라는 클래스를 만듭니다.\n",
        "- name: 이 도구의 이름입니다. AI는 이 이름으로 도구를 인식합니다.\n",
        "- description: 이 도구가 무엇을 하는지 설명합니다. AI는 이 설명을 읽고 언제 이 도구를 사용해야 할지 결정합니다.\n",
        "- \\_run: 이 도구가 실행될 때 실제로 동작하는 코드입니다. \\_run은 반드시 필요하며, 이름 앞에 언더스코어(_)가 있는 건 LangChain의 규칙입니다.\n",
        "- args_schema: 앞서 만든 입력 형식 클래스를 연결합니다. 이렇게 하면 AI가 이 도구에 필요한 입력 형식을 알 수 있습니다.\n",
        "\n",
        "왜 클래스가 두 개인가요?\n",
        "\n",
        "- 첫 번째 클래스(StockPriceCheckInput): 도구에 필요한 입력 데이터의 형식을 정의합니다.\n",
        "- 두 번째 클래스(StockPriceTool): 실제 도구 자체를 정의하고, 어떻게 동작할지 구현합니다.\n",
        "\n",
        "이렇게 분리하면 여러 도구가 같은 입력 형식을 공유하거나, 한 도구가 여러 입력 형식을 지원하는 등 더 유연하게 구성할 수 있습니다."
      ],
      "metadata": {
        "id": "VTBMquswQYs7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- _run 메서드는 LangChain의 BaseTool 클래스에서 요구하는 필수 메서드입니다.\n",
        "- 이 메서드는 도구가 실제로 실행될 때 호출되는 부분으로, 도구의 핵심 기능을 구현합니다. 따라서 실제로 실행되는 부분(함수)이어야 합니다."
      ],
      "metadata": {
        "id": "g73s--V7Pcwh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 랭체인을 이용한 Function Calling"
      ],
      "metadata": {
        "id": "co-Wa69TWAUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ChatMessage, FunctionMessage\n",
        "from langchain_classic.tools import MoveFileTool, format_tool_to_openai_function"
      ],
      "metadata": {
        "id": "LKlnewa8UP7H"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = ChatOpenAI(model=\"gpt-4o\")"
      ],
      "metadata": {
        "id": "7xUwdGJybkmK"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_openrouter_llm(\n",
        "    model=\"openai/gpt-oss-20b:free\",\n",
        "    # model=\"openai/gpt-oss-120b:free\",\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "xSrn7bEq1IcB"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# StockPriceTool를 랭체인이 사용하는 도구에 등록\n",
        "tools = [StockPriceTool()]\n",
        "\n",
        "# 도구를 OpenAI에서 이해할 수 있는 형식으로 서술 등록\n",
        "functions = [format_tool_to_openai_function(t) for t in tools]"
      ],
      "metadata": {
        "id": "Kz5J15J3bv08"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "functions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElmmJgpWi2ax",
        "outputId": "2e1eefd0-cdee-46b9-c2d9-6a089308704e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'get_stock_ticker_price',\n",
              "  'description': '주식 가격을 알아야 할 때 유용합니다. yfinance API에서 사용되는 주식 티커(종목 코드)를 입력해야 합니다.',\n",
              "  'parameters': {'properties': {'stockticker': {'description': 'Ticker symbol for stock or index',\n",
              "     'type': 'string'}},\n",
              "   'required': ['stockticker'],\n",
              "   'type': 'object'}}]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT-4o와 함수의 연결: Function Calling\n",
        "# GPT-4o에게 위의 '함수 명세'와 '사용자의 질의'를 입력\n",
        "# ai_message = model.predict_messages([HumanMessage(content=\"구글 주식의 가격을 알려줘\")], functions=functions)\n",
        "ai_message = model.invoke([HumanMessage(content=\"구글 주식의 가격을 알려줘\")], tools=functions)"
      ],
      "metadata": {
        "id": "KMtU1sWTbnZB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "a56ad76e-ef5f-4388-be00-29e0f8e7ab88"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1765843200000'}, 'provider_name': None}}, 'user_id': 'user_2uZsdCzhH6Ef352baQVbUsRAeVp'}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1703036966.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# GPT-4o에게 위의 '함수 명세'와 '사용자의 질의'를 입력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ai_message = model.predict_messages([HumanMessage(content=\"구글 주식의 가격을 알려줘\")], functions=functions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mai_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHumanMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"구글 주식의 가격을 알려줘\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m             cast(\n\u001b[1;32m    397\u001b[0m                 \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                 self.generate_prompt(\n\u001b[0m\u001b[1;32m    399\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1115\u001b[0m     ) -> LLMResult:\n\u001b[1;32m   1116\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m                 results.append(\n\u001b[0;32m--> 927\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    928\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1222\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraw_response\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"http_response\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_response\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m         if (\n\u001b[1;32m   1384\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_response_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 )\n\u001b[1;32m   1376\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m                 \u001b[0mraw_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_raw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_legacy_response.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extra_headers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLegacyAPIResponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1190\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1191\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1193\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1765843200000'}, 'provider_name': None}}, 'user_id': 'user_2uZsdCzhH6Ef352baQVbUsRAeVp'}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과로 나오는 것은 LLM의 답변이 아니라 어떤 함수를 어떤 파라미터로 호출해야 할 것인지를 알려준다.\n",
        "ai_message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYvQ1boLbqi2",
        "outputId": "5deb1088-497e-4328-bedd-623de3b0b390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"stockticker\":\"GOOGL\"}', 'name': 'get_stock_ticker_price'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 90, 'total_tokens': 111, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'function_call', 'logprobs': None}, id='run-a5b3a411-bce0-4a97-9939-55b838646d5d-0', usage_metadata={'input_tokens': 90, 'output_tokens': 21, 'total_tokens': 111, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 ai_message에서 'function_call'이라고 적힌 부분에 주목한다.  \n",
        "GPT-4o는 현재 주어진 함수 명세와 사용자의 질의를 고려하였을 때, `어떤 함수`를 `어떤 파라미터 값`으로 호출해야하는지 제안한다."
      ],
      "metadata": {
        "id": "OJDVCeMoxXn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ai_message.additional_kwargs['function_call']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANcp0LEIctol",
        "outputId": "8e93ef24-316b-4b36-9179-5bdeb0b8dd99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'arguments': '{\"stockticker\":\"GOOGL\"}', 'name': 'get_stock_ticker_price'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT-4o는 주어진 함수 명세와 사용자의 질의를 고려하였을 때  \n",
        "\n",
        "get_stock_tiker_price라는 함수를 {\"stockticker\":\"GOOGL\"}라는 파라미터로 호출해야 한다.  \n",
        "\n",
        "따라서 이를 실제로 호출한다."
      ],
      "metadata": {
        "id": "ADVXb62Kxlq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT-4o가 제안한 파라미터 값을 문자열로 추출\n",
        "ai_message.additional_kwargs['function_call'].get('arguments')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u8-X6L0_9pkd",
        "outputId": "492b531e-e54f-4680-8334-cfe1b4b65c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"stockticker\":\"GOOGL\"}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT-4o가 제안한 파라미터 값이 현재 문자열 타입이므로 파이썬의 Dictionary 형태로 읽는다.\n",
        "args = json.loads(ai_message.additional_kwargs['function_call'].get('arguments'))\n",
        "print(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSpgKqFDgUJf",
        "outputId": "bb187d05-870d-4d7a-c74a-76e2fc238b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'stockticker': 'GOOGL'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`구글 주식의 가격을 알려줘`의 질문에 대한 답변은 `{'stockticker': 'GOOGL'}`인 것이다.  \n",
        "이제 함수에 실제로 argument를 전달하여 함수의 결과를 얻어보자."
      ],
      "metadata": {
        "id": "yVmwXgu_9xNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Vrz1jDOtgzx",
        "outputId": "efe5208e-021a-42b0-f872-a3605bb9d37a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[StockPriceTool()]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOB-NM9597nx",
        "outputId": "37d75b49-12d3-4648-b5c9-d54b62941dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StockPriceTool()"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 함수 호출\n",
        "tool_result = tools[0](args)\n",
        "\n",
        "# 함수 호출 결과를 문자열로 변환\n",
        "tool_result = str(tool_result)\n",
        "print(tool_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNhjvQs2x7_S",
        "outputId": "f5e8b675-d362-4880-f047-5218251cd095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "170.92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-d59fedc09903>:2: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  tool_result = tools[0](args)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 함수 호출 결과를 최종 답변에 활용하기 위해서 랭체인의 형식으로 변환\n",
        "FunctionMessage(name='get_stock_ticker_price', content=tool_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSCjOF9fSRcM",
        "outputId": "6d1489b3-f02b-468a-c026-4b050b248ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FunctionMessage(content='170.92', additional_kwargs={}, response_metadata={}, name='get_stock_ticker_price')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_message = model.invoke([HumanMessage(content='구글 주식의 가격을 알려줘'), # 사용자의 질문\n",
        "                                        ai_message, # GPT-4o가 결정한 함수와 파라미터의 값\n",
        "                                        FunctionMessage(name='get_stock_ticker_price',content=tool_result)], # 함수 호출 결과\n",
        "                                        tools=functions) #함수의 명세"
      ],
      "metadata": {
        "id": "n5dlRG48OUAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각종 값들이 혼재되어져 있다. 실제 답변은 .content로 접근한다.\n",
        "final_message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XoYax4w-nUs",
        "outputId": "de25a485-528f-4e10-9fda-caff84152887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='현재 구글(알파벳) 주식의 가격은 170.92 달러입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 124, 'total_tokens': 148, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'stop', 'logprobs': None}, id='run-0635d362-3fd4-4b17-a5fc-5c70e832150b-0', usage_metadata={'input_tokens': 124, 'output_tokens': 24, 'total_tokens': 148, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AGDw7MfwQm2b",
        "outputId": "18e3da5c-c3bf-4220-c0df-54c306804260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'현재 구글(알파벳) 주식의 가격은 170.92 달러입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Calling 에이전트"
      ],
      "metadata": {
        "id": "9vqB7Ag3Pa33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0, model=\"gpt-4o\")"
      ],
      "metadata": {
        "id": "ThsbsO3qPnfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "open_ai_agent = initialize_agent(tools,\n",
        "                        llm,\n",
        "                        agent=AgentType.OPENAI_FUNCTIONS, # Funtion Calling Agent\n",
        "                        verbose=True)"
      ],
      "metadata": {
        "id": "0LKxJ6fcPeQf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5254abb0-c81c-4eda-9aee-e7b04d7fe42e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-3bfd662c9ca4>:1: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  open_ai_agent = initialize_agent(tools,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = open_ai_agent.run(\"구글 주식의 가격은?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAoc0zJ_PjIJ",
        "outputId": "0e0436b3-52e7-46cc-b52c-05331c9e8324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-98774a12db8f>:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = open_ai_agent.run(\"구글 주식의 가격은?\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_stock_ticker_price` with `{'stockticker': 'GOOGL'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m170.92\u001b[0m\u001b[32;1m\u001b[1;3m현재 구글(GOOGL) 주식의 가격은 $170.92입니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbz4US9b0pqY",
        "outputId": "5f12de9e-0aa3-43d4-a06e-3db0f3fd29fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 구글(GOOGL) 주식의 가격은 $170.92입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ReACT 에이전트 Vs. Function Calling 에이전트 비교\n",
        "\n",
        "- Function Calling은 CoT(생각 과정)이 없는 도구 호출 에이전트이다.\n",
        "- 이전에 ReACT 에이전트로 구현되었던 많은 프로젝트가 Function Calling으로 전환되고 있다. 이유는 CoT라는 선 과정이 토큰 소모와 느린 답변 속도에 영향을 미친다는 점때문에 모델 성능이 좋아지면서 CoT 없이도 도구 호출이 정확하게 가능한 경우가 많아졌기 때문이다.\n",
        "- 하지만 반대로 Function Calling이 파인 튜닝 후에도 잘 동작하지 않는다면 성능을 올리기 위해서 다시 CoT를 추가하여 ReACT 에이전트로 변경하는 것을 고려하기도 한다. CoT는 문제를 풀기 전 생각 과정을 추가하여 성능을 올리는 방법이라는 점을 기억한다.\n",
        "\n",
        "### 장점\n",
        "- ReACT 에이전트 대비 적은 토큰 필요. 답변 시 CoT가 없기 때문이다.\n",
        "- ReACT는 기본적으로 CoT를 하기 때문에 답변 속도가 느리다. CoT를 하는 동안에 시간은 계속 흐르고, CoT가 끝나야만 답변이 가능하기 때문이다. Function Calling은 더 빠른 답변을 얻을 수 있다.\n",
        "\n",
        "### 단점\n",
        "- CoT가 없기 때문에 제대로 작동하지 않을 경우 프롬프트 변경 등을 통한 커스터마이징이 쉽지 않다. Function Calling은 도구 설명 정도밖에 수정을 하지 못한다. 반면, ReACT 에이전트는 CoT라는 도구 호출 전 생각 과정이 있기때문에 해당 생각 부분에 대한 프롬프트 엔지니어링이 가능하기 때문이다.\n",
        "\n",
        "### 오픈 모델 파인 튜닝\n",
        "- 파인 튜닝이 가능한 상황이라면 특정 시나리오에 대해서 특정 함수를 호출하도록 학습하여 해당 도메인 특화 에이전트를 개발하는 것이 가능하다.  \n",
        "- 또한, 파인 튜닝이 가능하다면 ReACT 에이전트보다는 CoT가 없는 Function Calling으로 성능을 먼저 보는 것을 권장하며 (토큰 절약, 인퍼런스 속도를 감안하면 Function Calling이 더 낫기 때문.) 이후 성능이 오르지 않을 경우에 CoT를 추가하여 ReACT 형식으로 개조하는 방향으로 진행하는 것을 권한다."
      ],
      "metadata": {
        "id": "R9PVLXLmThML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 아래는 강의 영상에는 없지만 추가적으로 제공해드리는 자료입니다."
      ],
      "metadata": {
        "id": "DKJj4_RLzU2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 다수의 도구 시나리오"
      ],
      "metadata": {
        "id": "lohFBZ5HdbcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다수의 도구를 사용하는 Function Calling 에이전트를 만들어보자. 우선 두 개의 함수를 추가로 만든다.  \n",
        "\n",
        "- calculate_performance: 특정 주식과 기간을 주면 해당 기간 동안의 변동률을 계산한다.  \n",
        "- get_best_performing: 다수의 주식과 기간을 주면 해당 기간 동안 가장 좋은 성과를 보인 주식을 반환.\n"
      ],
      "metadata": {
        "id": "5nTM6nv41WbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "r-GTzpC9VOEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_performance(symbol, days_ago):\n",
        "    \"\"\"\n",
        "    주어진 기간 동안 특정 주식의 성과(가격 변동률)를 계산하는 함수.\n",
        "\n",
        "    :param symbol: 주식 심볼 (예: 'AAPL' for Apple Inc.)\n",
        "    :param days_ago: 몇 일 전부터의 성과를 계산할지 지정하는 정수\n",
        "    :return: 주식의 가격 변동률 (백분율)\n",
        "    \"\"\"\n",
        "    # 주어진 심볼에 대한 Ticker 객체 생성\n",
        "    ticker = yf.Ticker(symbol)\n",
        "\n",
        "    # 현재 날짜를 종료 날짜로 설정\n",
        "    end_date = datetime.now()\n",
        "\n",
        "    # 시작 날짜 계산 (현재로부터 days_ago일 전)\n",
        "    start_date = end_date - timedelta(days=days_ago)\n",
        "\n",
        "    # 날짜를 'YYYY-MM-DD' 형식의 문자열로 변환\n",
        "    start_date = start_date.strftime('%Y-%m-%d')\n",
        "    end_date = end_date.strftime('%Y-%m-%d')\n",
        "\n",
        "    # 지정된 기간의 주가 데이터 가져오기\n",
        "    historical_data = ticker.history(start=start_date, end=end_date)\n",
        "\n",
        "    # 시작 날짜의 종가와 마지막 날짜의 종가 가져오기\n",
        "    old_price = historical_data['Close'].iloc[0]\n",
        "    new_price = historical_data['Close'].iloc[-1]\n",
        "\n",
        "    # 퍼센트 변화율 계산\n",
        "    # ((새 가격 - 옛 가격) / 옛 가격) * 100\n",
        "    percent_change = ((new_price - old_price) / old_price) * 100\n",
        "\n",
        "    # 결과를 소수점 둘째 자리까지 반올림하여 반환\n",
        "    return round(percent_change, 2)"
      ],
      "metadata": {
        "id": "SCOinyJy4zPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_performing(stocks, days_ago):\n",
        "    \"\"\"\n",
        "    주어진 주식 목록에서 지정된 기간 동안 가장 좋은 성과를 보인 주식을 찾는 함수.\n",
        "\n",
        "    :param stocks: 주식 심볼 리스트 (예: ['AAPL', 'GOOGL', 'MSFT'])\n",
        "    :param days_ago: 몇 일 전부터의 성과를 계산할지 지정하는 정수\n",
        "    :return: 튜플 (최고 성과 주식 심볼, 해당 주식의 성과율)\n",
        "    \"\"\"\n",
        "    best_stock = None  # 최고 성과 주식을 저장할 변수\n",
        "    best_performance = None  # 최고 성과율을 저장할 변수\n",
        "\n",
        "    # 주어진 주식 목록을 순회\n",
        "    for stock in stocks:\n",
        "        try:\n",
        "            # 각 주식의 성과 계산\n",
        "            performance = calculate_performance(stock, days_ago)\n",
        "\n",
        "            # 현재 주식의 성과가 지금까지의 최고 성과보다 좋으면 업데이트\n",
        "            if best_performance is None or performance > best_performance:\n",
        "                best_stock = stock\n",
        "                best_performance = performance\n",
        "        except Exception as e:\n",
        "            # 성과 계산 중 오류 발생 시 오류 메시지 출력\n",
        "            print(f\"Could not calculate performance for {stock}: {e}\")\n",
        "\n",
        "    # 최고 성과 주식과 그 성과율 반환\n",
        "    return best_stock, best_performance"
      ],
      "metadata": {
        "id": "hIaVdcNF4v3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "get_best_performing의 함수 호출 예시를 봅시다."
      ],
      "metadata": {
        "id": "z0ALGu0V4tuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 분석할 주식 목록 정의\n",
        "stocks = ['AAPL', 'MSFT', 'GOOG']  # Apple, Microsoft, Google의 주식 심볼\n",
        "\n",
        "# 분석 기간 설정 (일 단위)\n",
        "days_ago = 90  # 지난 90일 동안의 성과를 분석\n",
        "\n",
        "# get_best_performing 함수를 호출하여 최고 성과 주식과 그 성과율 얻기\n",
        "best_stock, best_performance = get_best_performing(stocks, days_ago)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"지난 {days_ago}일 동안 가장 좋은 성과를 보인 주식은 {best_stock}이며, 성과율은 {best_performance}%입니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5Oaq-sr4Hk0",
        "outputId": "c2ae3a97-eb2c-441e-adbd-928398cf7719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "지난 90일 동안 가장 좋은 성과를 보인 주식은 AAPL이며, 성과율은 -1.94%입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 도구 추가"
      ],
      "metadata": {
        "id": "itlzbGZ5hTDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional, Type\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.tools import BaseTool\n",
        "\n",
        "##### 주식 가격 변동률 확인을 위한 도구 추가 #####\n",
        "##### 위에서 구현한 calculate_performance()를 내부적으로 사용 #####\n",
        "class StockChangePercentageCheckInput(BaseModel):\n",
        "    \"\"\"주식 가격 변동률 확인을 위한 입력 모델\"\"\"\n",
        "\n",
        "    stockticker: str = Field(..., description=\"주식 또는 지수의 티커 심볼\")\n",
        "    days_ago: int = Field(..., description=\"몇 일 전부터 확인할지 지정하는 정수\")\n",
        "\n",
        "class StockPercentageChangeTool(BaseTool):\n",
        "    \"\"\"주식 가격 변동률을 계산하는 도구\"\"\"\n",
        "\n",
        "    name: str = \"get_price_change_percent\"\n",
        "    description: str = \"주식 가치의 백분율 변화를 확인해야 할 때 유용합니다. yfinance API에서 사용되는 주식 티커와 변화를 확인할 일수를 입력해야 합니다.\"\n",
        "\n",
        "    def _run(self, stockticker: str, days_ago: int) -> float:\n",
        "        \"\"\"\n",
        "        주어진 주식의 가격 변동률을 계산합니다.\n",
        "        :param stockticker: 주식 티커 심볼\n",
        "        :param days_ago: 몇 일 전부터 계산할지 지정하는 정수\n",
        "        :return: 가격 변동률\n",
        "        \"\"\"\n",
        "        price_change_response = calculate_performance(stockticker, days_ago)\n",
        "        return price_change_response\n",
        "\n",
        "    args_schema: Optional[Type[BaseModel]] = StockChangePercentageCheckInput\n",
        "##### 주식 가격 변동률 확인을 위한 도구 추가 끝 #####"
      ],
      "metadata": {
        "id": "74147GgQP0fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### 최고 성과 주식 찾기를 위한 입력 도구 추가 #####\n",
        "##### 위에서 구현한 get_best_performing()를 내부적으로 사용 #####\n",
        "class StockBestPerformingInput(BaseModel):\n",
        "    \"\"\"최고 성과 주식 찾기를 위한 입력 모델\"\"\"\n",
        "\n",
        "    stocktickers: List[str] = Field(..., description=\"주식 또는 지수의 티커 심볼 리스트\")\n",
        "    days_ago: int = Field(..., description=\"몇 일 전부터 확인할지 지정하는 정수\")\n",
        "\n",
        "class StockGetBestPerformingTool(BaseTool):\n",
        "    \"\"\"여러 주식 중 최고 성과 주식을 찾는 도구\"\"\"\n",
        "\n",
        "    name: str = \"get_best_performing\"\n",
        "    description: str = \"특정 기간 동안 여러 주식의 성과를 확인해야 할 때 유용합니다. yfinance API에서 사용되는 주식 티커 리스트와 변화를 확인할 일수를 입력해야 합니다.\"\n",
        "\n",
        "    def _run(self, stocktickers: List[str], days_ago: int) -> tuple:\n",
        "        \"\"\"\n",
        "        주어진 주식 리스트에서 최고 성과 주식을 찾습니다.\n",
        "        :param stocktickers: 주식 티커 심볼 리스트\n",
        "        :param days_ago: 몇 일 전부터 계산할지 지정하는 정수\n",
        "        :return: 최고 성과 주식과 그 성과율\n",
        "        \"\"\"\n",
        "        price_change_response = get_best_performing(stocktickers, days_ago)\n",
        "        return price_change_response\n",
        "\n",
        "    args_schema: Optional[Type[BaseModel]] = StockBestPerformingInput\n",
        "##### 최고 성과 주식 찾기를 위한 입력 도구 추가 끝 #####"
      ],
      "metadata": {
        "id": "Y_f0z-4CRAth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "도구 3개를 모두 선택지로 제안합니다."
      ],
      "metadata": {
        "id": "f9DgINW95hOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [StockPriceTool(), StockPercentageChangeTool(), StockGetBestPerformingTool()]"
      ],
      "metadata": {
        "id": "SK9yuhQ9evMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igqJ4T73e4b1",
        "outputId": "58029dd2-c38a-45cb-dcf7-b61c28b2207b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[StockPriceTool(), StockPercentageChangeTool(), StockGetBestPerformingTool()]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 추가된 도구로부터 에이전트 호출"
      ],
      "metadata": {
        "id": "nerfnvS69_h2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0, model=\"gpt-4o\")"
      ],
      "metadata": {
        "id": "JZiw1RsTe_ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "open_ai_agent = initialize_agent(tools,\n",
        "                        llm,\n",
        "                        agent=AgentType.OPENAI_FUNCTIONS,\n",
        "                        verbose=True)"
      ],
      "metadata": {
        "id": "K_XbiPuve_ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "open_ai_agent.run(\"오늘 구글 주식은?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "122e312e-906b-466d-8e91-2ad069d1ffee",
        "id": "4YArEbHTe_ci"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_stock_ticker_price` with `{'stockticker': 'GOOGL'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m167.01\u001b[0m\u001b[32;1m\u001b[1;3m오늘 구글 주식의 가격은 $167.01입니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'오늘 구글 주식의 가격은 $167.01입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open_ai_agent.run(\"구글의 주가가 지난 90일 동안 상승했나요? 상승했다면 얼마나 상승했나요?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "GvDaOc3cfD6I",
        "outputId": "c141f355-1474-4239-f84c-85a5cde1e5fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_price_change_percent` with `{'stockticker': 'GOOGL', 'days_ago': 90}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m18.4\u001b[0m\u001b[32;1m\u001b[1;3m구글(GOOGL)의 주가는 지난 90일 동안 18.4% 상승했습니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'구글(GOOGL)의 주가는 지난 90일 동안 18.4% 상승했습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open_ai_agent.run(\"구글의 주가가 지난 3개월 동안 얼마나 상승했습니까?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "oYeRS67WfsfZ",
        "outputId": "6e878d63-d4bd-40bf-a5f0-4d714cb5cea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_price_change_percent` with `{'stockticker': 'GOOGL', 'days_ago': 90}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m-4.11\u001b[0m\u001b[32;1m\u001b[1;3m구글(GOOGL)의 주가는 지난 3개월 동안 약 4.11% 하락했습니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'구글(GOOGL)의 주가는 지난 3개월 동안 약 4.11% 하락했습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open_ai_agent.run(\"구글, 메타, 마이크로소프트 중 어느 주식이 지난 3개월 동안 가장 좋은 성과를 보였습니까?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "jHjQYThCf0TO",
        "outputId": "47a28f3a-6cf3-448e-edeb-38781f0e0820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_best_performing` with `{'stocktickers': ['GOOGL', 'META', 'MSFT'], 'days_ago': 90}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m('META', 6.81)\u001b[0m\u001b[32;1m\u001b[1;3m지난 3개월 동안 메타(META) 주식이 6.81% 상승하며 구글과 마이크로소프트보다 더 좋은 성과를 보였습니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'지난 3개월 동안 메타(META) 주식이 6.81% 상승하며 구글과 마이크로소프트보다 더 좋은 성과를 보였습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open_ai_agent.run(\"MSFT(마이크로소프트)의 주가가 지난 3개월 동안 얼마나 상승했습니까?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "C1rzyxrxjgY7",
        "outputId": "012cb27e-aa25-43aa-e6d1-9b3bb53384d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_price_change_percent` with `{'stockticker': 'MSFT', 'days_ago': 90}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m-11.01\u001b[0m\u001b[32;1m\u001b[1;3m마이크로소프트(MSFT)의 주가는 지난 3개월 동안 약 11.01% 하락했습니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'마이크로소프트(MSFT)의 주가는 지난 3개월 동안 약 11.01% 하락했습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open_ai_agent.run(\"비트코인이 지난 3개월 동안 얼마나 상승했습니까?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "eqvQgs-Wjmdy",
        "outputId": "a98f4281-b3d3-48dc-e953-aec06ced7127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_price_change_percent` with `{'stockticker': 'BTC-USD', 'days_ago': 90}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m-12.86\u001b[0m\u001b[32;1m\u001b[1;3m비트코인의 가격은 지난 3개월 동안 약 12.86% 하락했습니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'비트코인의 가격은 지난 3개월 동안 약 12.86% 하락했습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open_ai_agent.run(\"비트코인이 지난 3개월 동안 얼마나 상승했는지랑 구글이 5개월 간 얼마나 상승했는지 알려줘\")"
      ],
      "metadata": {
        "id": "CwZhZsH2pEW2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "e6a74ab8-6098-40dc-b508-ec413bcf18ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_price_change_percent` with `{'stockticker': 'BTC-USD', 'days_ago': 90}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m-12.86\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_price_change_percent` with `{'stockticker': 'GOOGL', 'days_ago': 150}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m2.59\u001b[0m\u001b[32;1m\u001b[1;3m비트코인은 지난 3개월 동안 약 12.86% 하락했습니다. 반면에 구글(알파벳)은 지난 5개월 동안 약 2.59% 상승했습니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'비트코인은 지난 3개월 동안 약 12.86% 하락했습니다. 반면에 구글(알파벳)은 지난 5개월 동안 약 2.59% 상승했습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}