{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d022ee04-9516-4bfb-9ea7-48d599354528",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://1591d381997255d4ea.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://1591d381997255d4ea.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://1591d381997255d4ea.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "from datasets import Dataset\n",
    "from qwen_vl_utils import process_vision_info  # 이미지/비디오 전처리를 위한 함수\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ----------------------------\n",
    "# 1. 모델 및 프로세서 로드\n",
    "# ----------------------------\n",
    "\n",
    "# Qwen2-VL-7B-Instruct 모델과 프로세서를 불러옵니다.\n",
    "model_id = \"Qwen/Qwen2-VL-7B-Instruct\"\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",          # 가능한 GPU에 할당\n",
    "    torch_dtype=torch.float16   # 메모리 효율성을 위한 float16 사용\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# 로라 어댑터(파인튜닝된 가중치)를 로드하고 모델에 적용합니다.\n",
    "adapter_path1 = \"./qwen2-7b-instruct-harmful-detector-2000/checkpoint-32\"\n",
    "model.load_adapter(adapter_path1, adapter_name=\"adapter1\")\n",
    "model.set_adapter(\"adapter1\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2. 프롬프트 및 메시지 형식 정의\n",
    "# ----------------------------\n",
    "\n",
    "# 시스템 메시지: 모델의 역할을 정의합니다.\n",
    "system_message = \"당신은 이미지와 텍스트의 '유해성(harmfulness)'을 판별하는 분류 모델입니다.\"\n",
    "\n",
    "# 프롬프트 템플릿: 모델이 유해성 여부를 판단할 때 참고할 기준 및 출력 형식을 지정합니다.\n",
    "prompt = \"\"\"입력으로 이미지 또는 ###텍스트가 주어지면, 해당 콘텐츠가 유해한지 여부를 '1' 또는 '0'으로 출력하세요.\"\"\"\n",
    "\n",
    "system_message = \"당신은 이미지와 텍스트의 '유해성(harmfulness)'을 판별하는 분류 모델입니다.\"\n",
    "\n",
    "# 프롬프트 템플릿: 모델이 유해성 여부를 판단할 때 참고할 기준 및 출력 형식을 지정합니다.\n",
    "prompt = \"\"\"입력으로 이미지 또는 ###텍스트가 주어지면, 해당 콘텐츠가 유해한지 여부를 \"1\" 또는 \"0\"으로 출력하세요.\n",
    "- 출력은 반드시 숫자 하나만(문자열 없이) 출력합니다.\n",
    "  - \"1\" : 유해(혐오·차별·폭력·선정성·기타 해악 가능성이 있다고 판단되는 경우)\n",
    "  - \"0\" : 비유해(문제 없다고 판단되는 경우)\n",
    "유해성(harmfulness)을 판단할 때는 아래 항목을 포함해 검토하세요:\n",
    "1. **혐오 표현 (Hate Speech)**\n",
    "   - 인종, 성별, 종교, 성적 지향, 장애 등을 근거로 특정 집단/개인을 비하·모욕·차별하는 언어/이미지\n",
    "   - 명백한 증오, 차별, 폭력 조장 등\n",
    "2. **직접적인 폭력·잔혹 행위**\n",
    "   - 극단적인 폭력 묘사(살해·자해·테러 등)\n",
    "   - 노골적으로 잔혹하거나 충격적인 내용\n",
    "3. **노골적 성적 콘텐츠**\n",
    "   - 명백히 선정적·음란한 묘사, 아동 성착취 등 불법적이거나 심각한 윤리적 문제가 있는 경우\n",
    "4. **사생활 침해, 불법 행위 조장**\n",
    "   - 명백한 사생활 침해, 범죄 또는 불법 행위를 조장하는 내용\n",
    "5. **기타 위험 요소**\n",
    "   - 위 항목 외에도, 사회적으로 유해하거나 심각한 해악을 유발할 수 있는 이미지·텍스트\n",
    "만약 콘텐츠가 위 기준 중 하나라도 충족하여 \"유해\"하다고 판단되면 \"1\"을,\n",
    "해당되지 않으면 \"0\"을 출력하십시오.\n",
    "출력은 오직 숫자 하나(1 또는 0)만 반환하고, 어떠한 추가 문구나 설명도 첨부하지 마십시오.\n",
    "\n",
    "###텍스트 :{text}\"\"\"\n",
    "\n",
    "# format_data 함수: CSV의 한 샘플 정보를 받아서 모델에 입력할 대화 메시지 형식으로 변환합니다.\n",
    "def format_data(sample):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",  # 시스템 역할 메시지\n",
    "                \"content\": [{\"type\": \"text\", \"text\": system_message}],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",  # 사용자 역할 메시지: 텍스트 프롬프트와 이미지 정보를 포함\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt.format(text=sample[\"translated\"]),\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"image\": sample[\"file_path\"],  # 이미지 파일 경로 (필요에 따라 PIL.Image 객체로 변경 가능)\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",  # 어시스턴트 역할 메시지: 실제 정답(ground truth) 포함\n",
    "                \"content\": [{\"type\": \"text\", \"text\": sample[\"is_hate\"]}],\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# 3. 모델 추론 함수 정의\n",
    "# ----------------------------\n",
    "\n",
    "# generate_description: 모델 추론을 수행하여 생성된 텍스트를 반환합니다.\n",
    "def generate_description(messages, model, processor):\n",
    "    # 채팅 템플릿을 적용하여 텍스트로 변환합니다.\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    # 이미지 및 비디오 입력을 전처리합니다.\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(model.device)\n",
    "\n",
    "    # 모델 추론: 새로운 토큰을 생성합니다.\n",
    "    generated_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=128,\n",
    "        top_p=0.95,\n",
    "        do_sample=True,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    # 원본 입력 토큰 수 만큼 잘라내어 생성된 부분만 추출합니다.\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids):]\n",
    "        for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    # 토큰을 텍스트로 디코딩합니다.\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=False\n",
    "    )\n",
    "    return output_text[0]\n",
    "\n",
    "# ----------------------------\n",
    "# 4. 데이터셋 로드 및 전처리\n",
    "# ----------------------------\n",
    "\n",
    "# CSV 파일에서 데이터를 로드하고, 필요한 전처리(숫자형 변환, 샘플 셔플, 인덱스 리셋 등)를 수행합니다.\n",
    "df = pd.read_csv('./data/final_df.csv')\n",
    "df[\"is_hate\"] = df[\"is_hate\"].astype(int)\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 데이터를 train과 test로 분할합니다.\n",
    "train_dataset, test_dataset = train_test_split(df, test_size=0.1, random_state=42)\n",
    "# test_dataset의 인덱스를 0부터 순차적으로 재설정합니다.\n",
    "test_dataset = test_dataset.reset_index(drop=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. 데이터 샘플 로드 함수\n",
    "# ----------------------------\n",
    "# 선택한 인덱스의 샘플 데이터를 불러와 이미지와 텍스트를 반환합니다.\n",
    "def load_sample(sample_index):\n",
    "    idx = int(sample_index)\n",
    "    row = test_dataset.iloc[idx]\n",
    "    image_path = row[\"file_path\"]\n",
    "    text = row[\"translated\"]\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except Exception as e:\n",
    "        image = None  # 이미지 로드 실패 시 None 반환\n",
    "    return image, text\n",
    "\n",
    "# ----------------------------\n",
    "# 6. 모델 추론 및 결과 출력 함수\n",
    "# ----------------------------\n",
    "\n",
    "# 선택한 샘플에 대해 모델 추론을 수행하고, 예측 결과와 실제 정답을 함께 반환합니다.\n",
    "def run_inference(sample_index, user_text):\n",
    "    idx = int(sample_index)\n",
    "    row = test_dataset.iloc[idx]\n",
    "\n",
    "    # CSV 샘플 데이터를 대화 형식 메시지로 변환 (실제 정답 포함)\n",
    "    messages = format_data(row)[\"messages\"]\n",
    "    # 모델을 통해 예측 텍스트를 생성합니다.\n",
    "    prediction_text = generate_description(messages, model, processor)\n",
    "\n",
    "    # 모델 예측 결과를 숫자로 변환한 후 해석합니다.\n",
    "    try:\n",
    "        prediction_int = int(prediction_text.strip())\n",
    "    except ValueError:\n",
    "        predicted_label = f\"예측 결과를 숫자로 변환하지 못했습니다: {prediction_text}\"\n",
    "    else:\n",
    "        if prediction_int == 1:\n",
    "            predicted_label = \"예측: 혐오 데이터입니다.\"\n",
    "        else:\n",
    "            predicted_label = \"예측: 비혐오 데이터입니다.\"\n",
    "\n",
    "    # CSV에 기록된 실제 정답을 확인합니다.\n",
    "    actual_int = int(row[\"is_hate\"])\n",
    "    if actual_int == 1:\n",
    "        actual_label = \"실제 정답: 혐오 데이터입니다.\"\n",
    "    else:\n",
    "        actual_label = \"실제 정답: 비혐오 데이터입니다.\"\n",
    "\n",
    "    # 예측 결과와 실제 정답을 함께 반환합니다.\n",
    "    return f\"{predicted_label}\\n{actual_label}\"\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Gradio UI 설정\n",
    "# ----------------------------\n",
    "\n",
    "# 사용자 인터페이스(UI)를 Gradio Blocks로 구성합니다.\n",
    "custom_css = \"\"\"\n",
    "<style>\n",
    "#title {\n",
    "    text-align: center;\n",
    "    font-size: 2em;\n",
    "    font-weight: bold;\n",
    "    margin: 20px 0 10px 0;\n",
    "}\n",
    "#subtitle {\n",
    "    text-align: center;\n",
    "    font-size: 1.1em;\n",
    "    color: #666;\n",
    "    margin-bottom: 30px;\n",
    "}\n",
    ".gr-button {\n",
    "    background-color: #4CAF50 !important;\n",
    "    color: white !important;\n",
    "    border: none !important;\n",
    "}\n",
    ".gr-textbox textarea {\n",
    "    min-height: 120px !important;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "with gr.Blocks(custom_css) as demo:\n",
    "    # 제목 및 부제목 표시\n",
    "    gr.Markdown(\"<div id='title'>이미지 & 텍스트 입력을 통한 모델 예측 데모</div>\")\n",
    "    gr.Markdown(\"<p id='subtitle'>아래에서 샘플을 선택하거나 직접 텍스트를 입력하고 예측을 실행해보세요.</p>\")\n",
    "\n",
    "    # 샘플 인덱스 선택 및 샘플 불러오기 버튼\n",
    "    with gr.Row():\n",
    "        sample_index = gr.Dropdown(\n",
    "            choices=[str(i) for i in test_dataset.index],\n",
    "            label=\"샘플 인덱스 선택\",\n",
    "            value=\"0\",\n",
    "            interactive=True\n",
    "        )\n",
    "        update_button = gr.Button(\"샘플 불러오기\")\n",
    "\n",
    "    # 이미지 및 텍스트 입력/출력 영역 구성\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            image_output = gr.Image(label=\"선택된 이미지\", elem_id=\"image_display\")\n",
    "        with gr.Column():\n",
    "            text_input = gr.Textbox(label=\"텍스트 입력\", placeholder=\"분석할 텍스트를 입력하세요.\")\n",
    "            predict_button = gr.Button(\"예측 실행\", variant=\"primary\")\n",
    "            result_output = gr.Textbox(label=\"예측 결과\", placeholder=\"결과가 여기에 표시됩니다.\")\n",
    "\n",
    "    # 버튼 클릭 시 함수 연결\n",
    "    update_button.click(fn=load_sample, inputs=sample_index, outputs=[image_output, text_input])\n",
    "    predict_button.click(fn=run_inference, inputs=[sample_index, text_input], outputs=result_output)\n",
    "\n",
    "# Gradio 앱 실행 (share=True 옵션으로 외부 접근 가능, debug=True로 디버깅 정보 표시)\n",
    "demo.launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df77b6-aab8-4e96-adfe-2f0da2a82d15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
